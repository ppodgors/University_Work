---
title: "List 1 - Multiple Regression and Multiple Testing"
subtitle: "Statistical Learning"
author: "Paulina Podg√≥rska"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

Let us generate the design matrix $X_{n \times p}=X_{1000 \times 950}$
such that its elements are iid random variables from
$N(0, \sigma=\frac{1}{\sqrt{1000}})$. Then we generate the vector of
values of the response variable $Y = X\beta+\epsilon,$ where
$\beta= (3,3,3,3,3,0, \dots, 0)^T$ and $\epsilon \sim N(0,I)$.\
We will perfmorm analysis using 4 models containing only:

-   first 10 columns of $X$ (p = 10)

-   first 100 columns of $X$ (p = 100)

-   first 500 columns of $X$ (p = 500)

-   all 950 columns (p = 950)

### Least square estimator of $\beta$

The formula for least square estimator of $\beta$ is:
$$\hat{\beta}_{LS} = argmin_{\beta \in \mathbb{R^p}}||Y-X\beta||^2 = (X'X)^{-1}X'Y.$$
$$\hat{\beta}_{LS} \sim N(\beta, \sigma^3(X'X)^{-1})$$

```{r echo=FALSE}
library(knitr)
#zad 1
set.seed(2020)
X<- matrix(rnorm(1000*950,0, 1/sqrt(1000)),1000,950)
beta<-c(rep(3,5), rep(0, 945))
set.seed(1227)
epsilon<- rnorm(1000)
Y <- X%*%beta+epsilon

coeffs = matrix(0,4,10)
tests = matrix(0,4,10)
red <- c(10,100,500,950)
sig_coeff = rep(0,4)
sd = rep(0,4)
con_int = rep(0,4)
TD = rep(0,4)
FD =rep(0,4)
TD_bon = rep(0,4)
FD_bon = rep(0,4)
TD_BH = rep(0,4)
FD_BH = rep(0,4)
for(i in 1:4){
  #a
  reg<-lm(Y~X[,1:red[i]]-1)
  CI = confint(reg,level=0.9)
  #b
  coeffs[i,] = summary(reg)$coefficients[1:10,1]
  test = summary(reg)$coefficients[,4]<0.1
  tests[i,] = summary(reg)$coefficients[1:10,4]
  sig_coeff[i]=sum(test)
  sd[i] = mean(sqrt(diag(vcov(reg))))
  con_int[i] = mean(CI[,2] - CI[,1])
  #c
  #i
  TD[i] = sum(test[1:5])
  FD[i] = sum(test[5:red[i]])
  #ii
  test_bon = summary(reg)$coefficients[,4]<0.1/red[i]
  TD_bon[i] = sum(test_bon[1:5])
  FD_bon[i] = sum(test_bon[5:red[i]])
  #iii
  pval = sort(summary(reg)$coefficients[,4],index=TRUE)
  BH = (pval$x<0.1*seq(1:red[i])/red[i])
  if (sum(BH)>0){
    len=max(which(BH))
    ind=pval$ix[1:len]
    TD_BH[i]=sum(ind<=5)
    FD_BH[i]=sum(ind>5)
  } else {
    TD_BH[i] =0
    FD_BH[i] =0
  }
}
coeffs = data.frame(round(coeffs,3))
colnames(coeffs)=c("$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$","$\\beta_8$","$\\beta_9$","$\\beta_{10}$")
rownames(coeffs) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
knitr::kable(coeffs, "pipe", caption = "First 10 least squares estimators for each model")

```

Next step is performing tests of significance of individual regression
coefficients at the significance level of $\alpha=0.1$.

$H_{0i}: \beta_i = 0$ $H_{1i}: \beta_i \neq 0$
$$T_i= \frac{\hat{\beta}_i}{s(\hat{\beta}_i)},$$ where
$s^2(\hat{\beta}_i) = s^2(X'X)^{-1}[i,i]$. In order to perform tests in
R we compare p-values to our $\alpha$ value.

```{r echo=FALSE}
tests = data.frame(round(tests,3))

for(j in 1:nrow(tests)){
  for(i in 1:ncol(tests)){
    tests[j,i] = ifelse(tests[j,i]<0.1, paste("\\color{red}{", round(as.numeric(tests[j,i]),3),"}",sep = ""),round(as.numeric(tests[j,i]),3))
  }
}

colnames(tests)=c("$\\beta_1$","$\\beta_2$","$\\beta_3$","$\\beta_4$","$\\beta_5$","$\\beta_6$","$\\beta_7$","$\\beta_8$","$\\beta_9$","$\\beta_{10}$")
rownames(tests) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
knitr::kable(tests, caption = "p-values for 10 first columns",align = c('cccccccccc'))

```

As we can see, for the first four models, the correct coefficients
tested as significant. Model with $950$ columns performs much worse.

### Standard deviation and length of confidence intervals

Let's examine the average standard deviation and the average length of
90% confidence intervals of our estimators.

```{r echo=FALSE}
df1 = data.frame(round(rbind(sd,con_int),3))
rownames(df1) = c("Avg. sd", "Avg. 90% CI")
colnames(df1) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
kable(df1, caption="Average standard deviation and average length of 90% confidence intervals")
```

Above values increase with the number of variables in a model. The model
with $950$ columns performs significantly worse.

### True and false discoveries

The next step is to examine the number of false and true discoveries for
different models.

#### Bonferroni correction

Its purpose is to minimize the number of Type I errors. It consists in
reducing the nominal significance level of each of the set of related
tests in direct proportion to their total number.\
We reject $H_0$ if $p_i \leqslant \frac{\alpha}{p}$, for
$i=1,\dots,p$.

#### Benjamini - Hochberg correction

It consists in sorting the $p_i$ values in descending order and finding
the $i_0$ index such that $i_0$ =
max{$i:p_i\leqslant\frac{i}{n}\alpha$}. Then we discard
$H_{(i)}:i\leqslant i_0$.

```{r echo=FALSE}
df2 = data.frame(rbind(TD,FD,TD_bon,FD_bon,TD_BH,FD_BH))
rownames(df2) = c("TD","FD","TD - Bonf.", "FD - Bonf","TD - B.H.", "FD - B.H.")
colnames(df2) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")

kable(df2, caption="True and false discoveries for different models")
```

The greater the number of variables, the fewer true discoveries are
detected and the more false discoveries. After applying the Bonferroni
correction and the Benjamini-Hochberg correction, the number of false
discoveries is zero. There are fewer true discoveries than in the case
of no correction.

## 500 repeats

In this section we will repeat above experiments 500 times on the basis
of which we will draw conclusions about the estimators.

### The average variance of the estimators

#### Inverse Wishart distribution

As we know, the formula for variance of the estimators of
regression coefficients is as follows:
$$s^2(\hat{\beta}_i) = s^2 (X'X)^{-1}[i,i].$$ If elements of $X$ are iid
from $N(0,\frac{1}{\sqrt{n}})$, then $X'X$ has a Wishart distribution.
$$X'X \sim W_p (n, diag(\frac{1}{n},...,\frac{1}{n})),$$
$$(X'X)^{-1}\sim W_p^{-1}(n, diag(n,...n)).$$ The $(X'X)^{-1}$ has the
inverse Wishart distribution. The expected values on the diagonal are
equal to $\frac{n}{n-p-1}$. Therefore, in our case the theoritical value
of variance of the estimators can be calculated with
$\hat{\sigma}^2 =\frac{n}{n-p-1}$.

```{r echo=FALSE, cashe=TRUE}
sig_coeff = rep(0,4)
sd = rep(0,4)
con_int = rep(0,4)
TD = rep(0,4)
FD =rep(0,4)
TD_bon = rep(0,4)
FD_bon = rep(0,4)
TD_BH = rep(0,4)
FD_BH = rep(0,4)
FWER_BH = rep(0,4)
FWER_bon = rep(0,4)
FDR_BH = rep(0,4)
FDR_bon = rep(0,4)
FWER = rep(0,4)
FDR = rep(0,4)
ile=500
for(j in 1:ile){
  X<- matrix(rnorm(1000*950,0, 1/sqrt(1000)),1000,950)
  epsilon<- rnorm(1000)
  Y <- X%*%beta+epsilon
  for(i in 1:4){
    #a
    reg<-lm(Y~X[,1:red[i]]-1)
    CI = confint(reg,level=0.9)
    #b
    test = summary(reg)$coefficients[,4]<0.1
    sig_coeff[i]=sum(test)
    sd[i] = sd[i] + mean(sqrt(diag(vcov(reg))))
    
    #n/(n-p-1) teoretyczna wariancja
    con_int[i] = con_int[i] + mean(CI[,2] - CI[,1])
    #c
    #i
    TD[i] = TD[i] + sum(test[1:5])
    FD[i] = FD[i] + sum(test[6:red[i]])
    if(sum(test[6:red[i]])>0){FWER[i] = FWER[i] +1}
    FDR[i] = FDR[i] + sum(test[6:red[i]])/max(1,sum(test))
    #ii
    test_bon = summary(reg)$coefficients[,4]<(0.1/red[i])
    TD_bon[i] = TD_bon[i]+sum(test_bon[1:5])
    FD_bon[i] = FD_bon[i]+sum(test_bon[6:red[i]])
    #iii
    pval = sort(summary(reg)$coefficients[,4],index=TRUE)
    BH = (pval$x<0.1*seq(1:red[i])/red[i])
    if (sum(BH)>0){
      len=max(which(BH))
      ind=pval$ix[1:len]
      TD_BH[i]= TD_BH[i]+sum(ind<=5)
      FD_BH[i]=FD_BH[i]+sum(ind>5)
      FDR_BH[i] = FDR_BH[i] + sum(ind>5)/max(1,(sum(ind<=5)+sum(ind>5)))
    }
    if(sum(test_bon[6:red[i]])>0){FWER_bon[i]=FWER_bon[i]+1}
    if(sum(ind>5)>0){FWER_BH[i]=FWER_BH[i]+1}
    
    FDR_bon[i] = FDR_bon[i] + sum(test_bon[6:red[i]])/max(1,sum(test_bon))
  }
}

sd = sd/ile
var = sd^2
con_int = con_int/ile
TD = TD/ile
FD=FD/ile
TD_bon = TD_bon/ile
FD_bon = FD_bon/ile
TD_BH = TD_BH/ile
FD_BH = FD_BH/ile
FWER_BH=FWER_BH/ile
FWER_bon=FWER_bon/ile
FDR_bon = FDR_bon/ile
FDR_BH = FDR_BH/ile
FWER = FWER/ile
FDR=FDR/ile
```

```{r echo=FALSE}
theor_var = rep(0,4)
for(i in 1:4){
  theor_var[i] = 1000/(1000-red[i]-1)
}
df3 = data.frame(round(rbind(var, theor_var),3))
colnames(df3) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
rownames(df3) = c("Avg. variance", "Theoretical value")
kable(df3, caption="Average variance and the theoritical value")
```

We can observe several times higher average variance for the model with
p = 950. We can conclude from this that in the case of a very large
number of variables (\>500) the estimation of parameters is more
difficult. In this situation, the parameter estimators are highly varied
and dispersed around the mean. Our calculated values are close to the
theoretical ones.

### The average length of the 90% interval

$$P_{H_0}(-q_{t(1-\alpha/2)}(n-p) \leqslant t_i \leqslant q_{t(1-\alpha/2)}(n-p)) = 1-\alpha$$
$$\hat{\beta}_i-q\cdot s(\hat{\beta}_i)\leqslant\beta_i \leqslant \hat{\beta}_i+q\cdot s(\hat{\beta}_i)$$
Therefore, we can calculate the width of the interval with:
$$2q\cdot s(\hat{\beta}_i).$$

```{r echo=FALSE}
CI_theor = rep(0,4)
for(i in 1:4){
  CI_theor[i] = 2*qt((1-0.05), 1000-red[i])*sqrt(theor_var[i])
}
df33 = data.frame(round(rbind(con_int, CI_theor),3))
colnames(df33) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
rownames(df33) = c("Avg. CI", "Theoretical value")

kable(df33,caption="Average length of the 90% confidence interval and the theoretical value")
```

Similar to the variance of the $\beta$ estimators, the average width of
the 90% confidence interval multiplies for p = 950,
making it difficult to correctly estimate the parameters for
multivariate models. Again the calculated values are close to the
theoretical ones.

### True and false discoveries, FWER and FDR

Theoretical number of False Discoveries:

-   no correction: $n_0\alpha = (p-k)\alpha$,

-   Bonferroni correction: $n_0 \frac{\alpha}{p} = (p-k)\frac{\alpha}{p}$, 

where $k = 5$. 

**FWER estimator** - Probability of one or
more false positives when tested repeatedly. \ FWER = P(Number of false
discoveries\>0)

Theoretical value for:

-   no correction: $1-(1-\alpha)^{(p-k)},$

-   Bonferroni correction: $1-(1-\alpha/p)^{(p-k)}.$

**FDR estimator** - average fraction of the number of false discoveries
in the group of all discoveries \ FDR = E[(Number of false
discoveries)/max(1,Number of discoveries)]

```{r echo=FALSE}
FD_ther = rep(0,4)
FWER_ther = rep(0,4)
FDBTH = rep(0,4)
FWERBTH = rep(0,4)
for(i in 1:4){
  FD_ther[i] = (red[i]-5)*0.1
  FWER_ther[i] = 1-(1-0.1)^(red[i]-5)
  FDBTH[i] = (red[i]-5)*(0.1/red[i])
  FWERBTH[i] = 1-(1-(0.1/red[i]))^(red[i]-5)
}
wo_adjusting = data.frame(round(cbind(TD,FD,FD_ther,FWER,FWER_ther ,FDR),3))
rownames(wo_adjusting) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
colnames(wo_adjusting) = c("TD","FD","Theo. FD", "FWER","Theo. FWER", "FDR")
BH_df = data.frame(round(cbind(TD_BH, FD_BH, FWER_BH,FDR_BH),3))
rownames(BH_df) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
colnames(BH_df) = c("TD","FD", "FWER", "FDR")

bon_df = data.frame(round(cbind(TD_bon,FD_bon,FDBTH, FWER_bon,FWERBTH ,FDR_bon),3))
rownames(bon_df) = c("$X_{10}$","$X_{100}$","$X_{500}$","$X_{950}$")
colnames(bon_df) = c("TD","FD","Theo. FD", "FWER","Theo. FWER", "FDR")
kable(wo_adjusting, caption="Without adjusting to multiple testing",align = c('cccccc'))
```
```{r echo=FALSE}

kable(bon_df, caption="Bonferroni correction",align = c('cccccc'))
```
```{r echo=FALSE}
kable(BH_df,caption="Benjamini-Hochberg correction",align = c('cccc'))
```

We get the lowest number of false discoveries and FWER using Bonferroni correction. This method also gives us the lowest number of true discoveries. Because of that we can lose valuable information about data, unless our biggest concern is the amount of false discoveries. As expected, without adjusting to multiple testing we get the worst results -- FWER and FDR are really high. Benjamini-Hochberg method is a choice in a situation when we want to achieve a low number of false discoveries, not at a cost of true discoveries -- FWER and FDR are higher than with Bonferroni correction but TD is also higher. Overall, regardless of the method we choose, the more the number of coefficients the harder it is to correctly predict their significance. 
